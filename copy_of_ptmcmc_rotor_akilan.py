# -*- coding: utf-8 -*-
"""Copy of PTMCMC_Rotor_Akilan.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1M_i1YuQuaWJjEa9tRfnMyswuBEj6Rn_j
"""

# Commented out IPython magic to ensure Python compatibility.
from pprint import pprint
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
!pip install -U corner
import corner
!pip install -U emcee
import emcee
import tensorflow as tf
# import tensorflow.compat.v2 as tf
# tf.enable_v2_behavior()

import tensorflow_probability as tfp

sns.reset_defaults()
sns.set_context(context='talk',font_scale=0.7)
plt.rcParams['image.cmap'] = 'viridis'

# %matplotlib inline

tfd = tfp.distributions
tfb = tfp.bijectors
from tensorflow_probability.python.mcmc import kernel as kernel_base
# from tf.math import polyval

def npf(array_):
  return np.array([float(x) for x in array_])

dtype=tf.float32
def tfc(arr):
  return tf.constant(arr, dtype=dtype)

SEED = 42229
OUTPUT_DIM = 4
NUM_PARAMETERS = 23
MEASUREMENT_ERROR = tfc([4., 6., 8., 9.]) # shape = (OUTPUT_DIM,)
THETA_VALUES = tfc([1., 2., 3.]) # shape = (number_of_theta_values,)
rng = np.random.default_rng(SEED)

true_parameters = tf.cast(tf.linspace(1, 10, NUM_PARAMETERS), dtype)[tf.newaxis, ...] # shape = (1, NUM_PARAMETERS)
num_temperatures = 7
inverse_temperatures = 0.6**tf.range(num_temperatures, dtype=dtype)
num_posterior_samples = 5000
num_burn_in_steps = 500
parameter_labels = [chr(x) for x in range(ord('A'), ord('A') + NUM_PARAMETERS)]
step_size = tf.reshape(tf.repeat(tf.constant(.1, dtype=dtype), num_temperatures * NUM_PARAMETERS), (num_temperatures, NUM_PARAMETERS))
initial_state = tf.zeros(NUM_PARAMETERS, dtype=dtype)

# theta.shape: (batch_theta, theta_size = 1)
# parameters.shape: (batch_parameters, parameters_size = 3)
# shape: (batch_theta, batch_parameters, 4)
# result[:, j, i] gives ith sensor channel (i in {0, 1, 2, 3}) and jth set of parameters (j in {0, 1, ..., 22}) for all theta.
@tf.function
def model(theta, parameters):
  powers = tf.pow(theta[..., tf.newaxis], tf.reshape(tf.range(NUM_PARAMETERS, dtype=dtype), (1, -1)))[:, tf.newaxis, ...]
  print(powers.shape)
  intermediate_parameters = tf.cast(tf.transpose(parameters)[tf.newaxis, ...], dtype=dtype)
  print(intermediate_parameters.shape)
  result = tf.linalg.matmul(powers, intermediate_parameters)[:, 0, ...]

  return tf.cast(tf.stack((result, result * 2., result * 3., result * 4.), axis=-1), dtype=dtype)
  # return tf.cast(tf.stack((result, result * 2.), axis=-1), dtype=dtype)
  # return result[..., tf.newaxis]

thetas = THETA_VALUES
ys = model(thetas, true_parameters)

@tf.function
def lnprior(parameters):
  return tfc(0.0)

@tf.function
def unnormalized_posterior(parameters):
  # print("predicted values shape", model(thetas, parameters).shape)
  print("model(thetas, parameters).shape", model(thetas, parameters).shape)
  print("parameters.shape", parameters.shape)
  print("MEASUREMENT_ERROR.shape", MEASUREMENT_ERROR.shape)
  # print(model(thetas, parameters)[1, 0, 0])
  # print(model(thetas, parameters)[:, 1, 0])
  # print(model(thetas, parameters)[:, 0, 1])
  likelihoods = tfd.MultivariateNormalDiag(loc=model(thetas, parameters), scale_diag=MEASUREMENT_ERROR)
  print("likelihoods log prob shape", likelihoods.log_prob(ys).shape)
  # print("reduced sum, with specified axis shape", tf.reduce_sum(likelihoods.log_prob(ys), axis=0).shape)
  return (lnprior(parameters) +
          tf.reduce_sum(likelihoods.log_prob(ys), axis=0)) # axis=0 is IMPORTANT! sum over theta, not over the parameter choices.

# print(tf.concat((true_parameters, true_parameters + 1.), axis=0))
print(unnormalized_posterior(tf.concat((true_parameters, true_parameters + 1., true_parameters + 2., true_parameters + 3.), axis=0)))

def make_kernel_fn(target_log_prob_fn):
  return tfp.mcmc.HamiltonianMonteCarlo(
    target_log_prob_fn=target_log_prob_fn,
    step_size=step_size,
    num_leapfrog_steps=2)

@tf.function
def run_chain(kernel, initial_state, num_posterior_samples=num_posterior_samples, num_burnin_steps=num_burn_in_steps):
  return tfp.mcmc.sample_chain(
    num_results=num_posterior_samples,
    num_burnin_steps=num_burnin_steps,
    current_state=initial_state,
    kernel=kernel,
    trace_fn=lambda current_state, kernel_results: kernel_results)

remc = tfp.mcmc.ReplicaExchangeMC(
    target_log_prob_fn=unnormalized_posterior,
    inverse_temperatures=inverse_temperatures,
    make_kernel_fn=make_kernel_fn)

samples, kernel_results = run_chain(remc, initial_state)

fig = corner.corner(samples.numpy(),show_titles=True,labels=parameter_labels,plot_datapoints=True,quantiles=[0.16, 0.5, 0.84], truths=true_parameters.numpy()[0])
print(samples.numpy().shape)
# Save the figure
fig.savefig("your_plot_filename.png", dpi=300, bbox_inches="tight")

print(true_parameters.numpy().shape)